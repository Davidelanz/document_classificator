{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "The available data comes from  a small toy dataset based on the [RVL-CDIP Dataset](http://www.cs.cmu.edu/~aharley/rvl-cdip/). The dataset contains 100 documents of 4 classes: \n",
    "- “resumee”,\n",
    "- “invoice”, \n",
    "- “letter”, \n",
    "- “email.\n",
    "\n",
    "For each document we have:\n",
    "- image, \n",
    "- PDF \n",
    "- OCR in our proprietary dictionary format\n",
    "\n",
    "The dictionaries come consolidated in the ``document_type_data.csv`` file, alongside with the text of the document:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ocr</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['Chaikin, ', 'Karen ', 'n ', \"O' \", 'o ', 'Fr...</td>\n",
       "      <td>email</td>\n",
       "      <td>2085136614c.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['&gt; ', 'Jenny, ', 'After ', 'speaking ', 'with...</td>\n",
       "      <td>email</td>\n",
       "      <td>2085136814a.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['Please ', 'call ', 'with ', 'any ', 'questio...</td>\n",
       "      <td>email</td>\n",
       "      <td>2085140145a.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['2085158326 ', 'Williams, ', 'Carrie ', 'T. '...</td>\n",
       "      <td>email</td>\n",
       "      <td>2085158326.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['GJ ', '□3 ', 'A ', 'nice ', 'ending ', 'to '...</td>\n",
       "      <td>email</td>\n",
       "      <td>2085161311b.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['CURRICULUM ', 'VITAE ', 'NILANJAN ', 'ROY ',...</td>\n",
       "      <td>resumee</td>\n",
       "      <td>50701639-1640.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['BIOGRAPHICAL ', 'SKETCH ', 'Mark ', 'S. ', '...</td>\n",
       "      <td>resumee</td>\n",
       "      <td>50712092-2093.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['May. ', '1997 ', 'CURRICULUM ', 'VITAE ', 'E...</td>\n",
       "      <td>resumee</td>\n",
       "      <td>50735851-5852.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['I ', 'CURRICULUM ', 'VITAE ', '* ', 'NAbE: '...</td>\n",
       "      <td>resumee</td>\n",
       "      <td>80412888_80412908.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>{'pageImages': [{'__typename': 'Image', 'width...</td>\n",
       "      <td>['VITA ', 'e-mail ', 'Professor, ', 'School ',...</td>\n",
       "      <td>resumee</td>\n",
       "      <td>98032348_2356.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                                ocr  \\\n",
       "0            0  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "1            1  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "2            2  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "3            3  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "4            4  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "..         ...                                                ...   \n",
       "95          95  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "96          96  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "97          97  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "98          98  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "99          99  {'pageImages': [{'__typename': 'Image', 'width...   \n",
       "\n",
       "                                                 text    label  \\\n",
       "0   ['Chaikin, ', 'Karen ', 'n ', \"O' \", 'o ', 'Fr...    email   \n",
       "1   ['> ', 'Jenny, ', 'After ', 'speaking ', 'with...    email   \n",
       "2   ['Please ', 'call ', 'with ', 'any ', 'questio...    email   \n",
       "3   ['2085158326 ', 'Williams, ', 'Carrie ', 'T. '...    email   \n",
       "4   ['GJ ', '□3 ', 'A ', 'nice ', 'ending ', 'to '...    email   \n",
       "..                                                ...      ...   \n",
       "95  ['CURRICULUM ', 'VITAE ', 'NILANJAN ', 'ROY ',...  resumee   \n",
       "96  ['BIOGRAPHICAL ', 'SKETCH ', 'Mark ', 'S. ', '...  resumee   \n",
       "97  ['May. ', '1997 ', 'CURRICULUM ', 'VITAE ', 'E...  resumee   \n",
       "98  ['I ', 'CURRICULUM ', 'VITAE ', '* ', 'NAbE: '...  resumee   \n",
       "99  ['VITA ', 'e-mail ', 'Professor, ', 'School ',...  resumee   \n",
       "\n",
       "                file_name  \n",
       "0         2085136614c.pdf  \n",
       "1         2085136814a.pdf  \n",
       "2         2085140145a.pdf  \n",
       "3          2085158326.pdf  \n",
       "4         2085161311b.pdf  \n",
       "..                    ...  \n",
       "95      50701639-1640.pdf  \n",
       "96      50712092-2093.pdf  \n",
       "97      50735851-5852.pdf  \n",
       "98  80412888_80412908.pdf  \n",
       "99      98032348_2356.pdf  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/document_type_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'json.decoder.JSONDecodeError'> :  Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    json.loads(df.loc[0, \"ocr\"])\n",
    "except Exception as e:\n",
    "    print(type(e), \": \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'json.decoder.JSONDecodeError'> :  Expecting value: line 1 column 2 (char 1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    json.loads(df.loc[0, \"text\"])\n",
    "except Exception as e:\n",
    "    print(type(e), \": \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warning**: there are problems with ``\"`` for some fields in the json ``ocr`` and ``text`` strings, hence, we will just use ``text`` information stripping out any non-alphanumeric character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     chaikin  karen  n  o  o  from  sent  to  subje...\n",
       "1       jenny  after  speaking  with  elisa  about  ...\n",
       "2     please  call  with  any  questions  thanks  nw...\n",
       "3     2085158326  williams  carrie  t  lbco  will  b...\n",
       "4     gj  3  a  nice  ending  to  the  story  below ...\n",
       "                            ...                        \n",
       "95    curriculum  vitae  nilanjan  roy  name  1st  o...\n",
       "96    biographical  sketch  mark  s  ptashne  profes...\n",
       "97    may  1997  curriculum  vitae  education  and  ...\n",
       "98    i  curriculum  vitae    nabe  emil  r  unanue ...\n",
       "99    vita  email  professor  school  of  social  we...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_series = df[\"text\"].str.lower().apply(lambda x : re.sub(r'[^a-zA-Z0-9 ]', '', x))\n",
    "text_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "Lastly, we need to encode the labels for each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'email', 1: 'invoice', 2: 'letter', 3: 'resumee'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code2label = dict(enumerate(df['label'].astype(\"category\").cat.categories ) )\n",
    "code2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email': 0, 'invoice': 1, 'letter': 2, 'resumee': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2code = {v : k for k, v in code2label.items()}\n",
    "label2code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To make everything simpler, we prepare the dataframe with just the data we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chaikin  karen  n  o  o  from  sent  to  subje...</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jenny  after  speaking  with  elisa  about  ...</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please  call  with  any  questions  thanks  nw...</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2085158326  williams  carrie  t  lbco  will  b...</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gj  3  a  nice  ending  to  the  story  below ...</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>curriculum  vitae  nilanjan  roy  name  1st  o...</td>\n",
       "      <td>resumee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>biographical  sketch  mark  s  ptashne  profes...</td>\n",
       "      <td>resumee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>may  1997  curriculum  vitae  education  and  ...</td>\n",
       "      <td>resumee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>i  curriculum  vitae    nabe  emil  r  unanue ...</td>\n",
       "      <td>resumee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>vita  email  professor  school  of  social  we...</td>\n",
       "      <td>resumee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text    label\n",
       "0   chaikin  karen  n  o  o  from  sent  to  subje...    email\n",
       "1     jenny  after  speaking  with  elisa  about  ...    email\n",
       "2   please  call  with  any  questions  thanks  nw...    email\n",
       "3   2085158326  williams  carrie  t  lbco  will  b...    email\n",
       "4   gj  3  a  nice  ending  to  the  story  below ...    email\n",
       "..                                                ...      ...\n",
       "95  curriculum  vitae  nilanjan  roy  name  1st  o...  resumee\n",
       "96  biographical  sketch  mark  s  ptashne  profes...  resumee\n",
       "97  may  1997  curriculum  vitae  education  and  ...  resumee\n",
       "98  i  curriculum  vitae    nabe  emil  r  unanue ...  resumee\n",
       "99  vita  email  professor  school  of  social  we...  resumee\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"label\"]].copy()\n",
    "df.loc[:, \"text\"] = text_series\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing torchtext dataset\n",
    "\n",
    "The following process is adapted from Pytorch's [Text Sentiment n-Grams classification](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html) page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With torchtext, we can easily build a vocabulary with the raw iterator by using the built-in factory function ``build_vocab_from_iterator``. This function accepts an iterator that yield list or iterator of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('email',\n",
       " 'chaikin  karen  n  o  o  from  sent  to  subject  chaikin  karen  monday  july  16  2001  724  pm  plombadogtnadcomcom  re  rfp  and  op  plan  kc  youth  smoking  prevention  hj  q  oe  vi  phil  thanks  for  all  of  these  note  that  i  cannot  open  the  marked  version  of  the  op  plan  can  you  please  reconvert  to  a  pdf  and  resend  thanks ')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_iterator = df.set_index(\"label\")[\"text\"].iteritems()\n",
    "next(text_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(yield_tokens(text_iterator), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a vocabulary converting a list of tokens into integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[756, 0, 33, 0, 32]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['now', \"I\", \"will\", \"tokenize\", \"this\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare the Prepare processing pipeline with the tokenizer and vocabulary. The text and label pipelines will be used to process the raw data strings from the dataset iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: label2code[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The text pipeline converts a text string into a list of integers based on the lookup table defined in the vocabulary. \n",
    "- The label pipeline converts the label into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[756, 7, 33, 0, 32]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('now I will tokenize this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline('email')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1585,\n",
       " 88,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 64,\n",
       " 4,\n",
       " 47,\n",
       " 0,\n",
       " 1585,\n",
       " 332,\n",
       " 277,\n",
       " 856,\n",
       " 298,\n",
       " 0,\n",
       " 70,\n",
       " 0,\n",
       " 75,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 769,\n",
       " 0,\n",
       " 1176,\n",
       " 245,\n",
       " 774,\n",
       " 3790,\n",
       " 484,\n",
       " 1671,\n",
       " 836,\n",
       " 1083,\n",
       " 162,\n",
       " 8,\n",
       " 115,\n",
       " 1,\n",
       " 190,\n",
       " 394,\n",
       " 18,\n",
       " 7,\n",
       " 3018,\n",
       " 0,\n",
       " 2,\n",
       " 4231,\n",
       " 1881,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 769,\n",
       " 155,\n",
       " 11,\n",
       " 39,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 162]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(df.iloc[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline(df.iloc[0][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then write a custom torch dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocTextDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    @staticmethod\n",
    "    def yield_tokens(data_iter):\n",
    "        for _, text in data_iter:\n",
    "            yield tokenizer(text)\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, code2label : dict = None):\n",
    "        self.df = df     \n",
    "        if code2label is None:\n",
    "            self.code2label = dict(enumerate(df['label'].astype(\"category\").cat.categories ) )\n",
    "        else:\n",
    "            self.code2label = code2label\n",
    "        self.label2code = {v : k for k, v in code2label.items()}\n",
    "        text_iterator = self.df.set_index(\"label\")[\"text\"].iteritems()\n",
    "        tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "        self.vocab = torchtext.vocab.build_vocab_from_iterator(self.yield_tokens(text_iterator), specials=[\"<unk>\"])\n",
    "        self.vocab.set_default_index(self.vocab[\"<unk>\"])\n",
    "        self.text_pipeline = lambda x: self.vocab(tokenizer(x))\n",
    "        self.label_pipeline = lambda x: self.label2code[x]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        label = self.label_pipeline(self.df.iloc[idx][\"label\"])\n",
    "        text = self.text_pipeline(self.df.iloc[idx][\"text\"])\n",
    "        sample = {\"text\": torch.LongTensor(text), \"label\": torch.LongTensor([label])}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': tensor([1378,  736,   86,   15,   15,   19,   62,    4,   43, 1378,  736,  285,\n",
       "          234,  623,  258, 2569,   64, 4671,   72, 4900,    3, 1683,  484, 4033,\n",
       "          847,  212,  586, 1547,  401, 1072,  617,  773,  139,    8,  108,    1,\n",
       "          169,  336,   18,    7, 1369, 4520,    2, 1631, 1169,    1,    2, 1683,\n",
       "          484,  145,   11,   38, 4837,    4,    6, 4609,    3, 4875,  139]),\n",
       " 'label': tensor([0])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DocTextDataset(df, code2label)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will use pytorch, we will need to use a \n",
    "[DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader)\n",
    "Before sending the loaded batch of samples data to the model, we can use DataLoader's ``collate_fn`` **to process the batch**.\n",
    "\n",
    "> **Warning**: ``collate_fn`` is declared as a top level def, ensuring that the function is available in each DataLoader's worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for sample in batch:\n",
    "        _label = sample[\"label\"] \n",
    "        _text = sample[\"text\"]\n",
    "        label_list.append(_label)\n",
    "        processed_text = torch.LongTensor(_text)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return {\n",
    "        \"label\" : label_list.to(device), \n",
    "        \"text\" : text_list.to(device), \n",
    "        \"offset\" : offsets.to(device)    \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to split the dataframe in train-validation-test splits:\n",
    "- 60% - train set,\n",
    "- 20% - validation set,\n",
    "- 20% - test set\n",
    "\n",
    "Then, we initialize the corresponding DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: 60 20 20\n"
     ]
    }
   ],
   "source": [
    "# shuffle df\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "# split it\n",
    "train_df, val_df, test_df = np.split(df, [int(.6*len(df)), int(.8*len(df))])\n",
    "# initialize datasets\n",
    "train_dataset = DocTextDataset(train_df, code2label)\n",
    "val_dataset = DocTextDataset(val_df, code2label)\n",
    "test_dataset = DocTextDataset(test_df, code2label)\n",
    "print(\"Sizes:\", len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test if the DataLoader works correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([3, 2, 2, 1, 1, 1, 0, 3]),\n",
       " 'text': tensor([   3,    5,  402,  ..., 2516,  174,  252]),\n",
       " 'offset': tensor([   0,  249,  369,  497,  626,  789, 1020, 1140])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
